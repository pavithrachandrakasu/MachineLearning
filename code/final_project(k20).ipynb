{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: \n",
      "\n",
      "{u'asin': u'0006428320',\n",
      " u'helpful': [0, 0],\n",
      " u'overall': 3.0,\n",
      " u'reviewText': u'The portfolio is fine except for the fact that the last movement of sonata #6 is missing. What should one expect?',\n",
      " u'reviewTime': u'03 11, 2014',\n",
      " u'reviewerID': u'A1YS9MDZP93857',\n",
      " u'reviewerName': u'John Taylor',\n",
      " u'summary': u'Parts missing',\n",
      " u'unixReviewTime': 1394496000}\n"
     ]
    }
   ],
   "source": [
    "def load_file(path):\n",
    "    \"\"\" Load the file and extract the data into a list in json format \"\"\"\n",
    "    d=[]\n",
    "    with open(path) as json_data:\n",
    "        for line in json_data:\n",
    "            d.append(json.loads(line))\n",
    "        json_data.close()\n",
    "    return d\n",
    "    #pprint(d)\n",
    "data =load_file(r'reviews_Musical_Instruments.json')\n",
    "print \"Sample data: \\n\"\n",
    "pprint(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users  500176\n",
      "Number of items 500176\n",
      "Number of ratings 500176\n",
      "Number of user reviews 500176\n"
     ]
    }
   ],
   "source": [
    "def create_lists_from_main_data(main_data):\n",
    "    \"\"\" Extract the uses ID, item ID, Reviews, Ratings from the dataset \"\"\"\n",
    "    item = []\n",
    "    user_id = [ ]\n",
    "    rating = [ ]\n",
    "    reviews = [ ]\n",
    "    for each in main_data:\n",
    "        item.append(\"item-\"+each['asin']) # appending 'item-' to the item ID for better understanding \n",
    "        user_id.append(each['reviewerID'])\n",
    "        rating.append(each['overall'])\n",
    "        reviews.append(each['reviewText'])\n",
    "    return item,rating,reviews,user_id\n",
    "item,rating,reviews,user_id=create_lists_from_main_data(data)\n",
    "print \"Number of users \",len(user_id)\n",
    "print \"Number of items\", len(item)\n",
    "print \"Number of ratings\", len(rating)\n",
    "print \"Number of user reviews\",len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data set: 339231\n",
      "\n",
      "Sample format of data inside dictionary:\n",
      "AX4PH3FN2FEQO {u'item-B004K3AMO2': (3.0, u'This cab is clearly advertised here as containing a tweeter and 4 ohm impedance. I recently received this item and it does not have a tweeter nor is it 4 ohms. It clearly states on the back of the cab that it is 8 ohms. It also does not have speakon connectors, it only has one 1/4 inch connector on the back. The photo is misleading as well as it clearly shows a tweeter. Apparently this is a bare bones simple 4x10 cab, which is why it may be labeled as \"extended range.\" BE WARNED THAT THIS ITEM IS NOT WHAT IS ADVERTISED. However, regardless of it\\'s simplicity, it does have that good eden sound (at a shockingly low price) and when paired with my 2x10 with tweeter I get a great sound combination. In a way it is good that the cab is 8 ohms because my 2x10 is also 8 ohms, together I get the 4 ohms needed for my amp.')}\n"
     ]
    }
   ],
   "source": [
    "def create_nested_dict(main_key,nested_key,rating,reviews):\n",
    "    \"\"\" Storing the data set in python dictionary (user { item: (rating,reviews)}\"\"\"\n",
    "    \n",
    "    data = defaultdict(dict)\n",
    "    for i in range(0,len(user_id)):\n",
    "        data[main_key[i]][nested_key[i]] = (rating[i],reviews[i])  \n",
    "        \n",
    "    cf_data = defaultdict(dict)\n",
    "    for i in range(0,len(user_id)):\n",
    "        cf_data[main_key[i]][nested_key[i]] = rating[i]  \n",
    "    return cf_data, data    \n",
    "\n",
    "#creating user->item->rating dictionary\n",
    "cf_data , user_dict = create_nested_dict(user_id,item,rating,reviews) \n",
    "\n",
    "print \"Size of the data set:\", len(user_dict)\n",
    "\n",
    "print \"\\nSample format of data inside dictionary:\"\n",
    "for key in user_dict:\n",
    "    print key , user_dict[key]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dict)filtered users with rating as values-> 420\n",
      "(list)unique items for filtered users with rating as values-> 11664\n"
     ]
    }
   ],
   "source": [
    "def filter_data(dict_to_filter,threshold):\n",
    "    \"\"\"  returns a filtered dictionary and a unique list of nested keys in that filtered dictionary \"\"\"\n",
    "    \n",
    "    #creating new dictionary for storing only filtered items\n",
    "    filtered_dict={ }   \n",
    "    \n",
    "    # create a dictionary of {main_key{nested_key: value}} according to the threshhold value\n",
    "    for i,each in enumerate(dict_to_filter):\n",
    "        if len(dict_to_filter[each])> threshold:\n",
    "            filtered_dict[each] = dict_to_filter[each]\n",
    "    \n",
    "    # create a list of unique nested_keys(users/movies) that are in the filtered dictionary\n",
    "    unique_nested_keys_in_filtered_dict=[]\n",
    "    for user in filtered_dict:\n",
    "        for item in filtered_dict[user]:\n",
    "            if item not in unique_nested_keys_in_filtered_dict:\n",
    "                unique_nested_keys_in_filtered_dict.append(item)\n",
    "    \n",
    "    return filtered_dict,unique_nested_keys_in_filtered_dict\n",
    "\n",
    "#1.filter users as per the threshold \n",
    "#2.find unique number of items for filtered users\n",
    "\n",
    "filtered_users,unique_items_for_filtered_user=filter_data(user_dict,20)\n",
    "print \"(dict)filtered users with rating as values->\",len(filtered_users)\n",
    "print \"(list)unique items for filtered users with rating as values->\",len(unique_items_for_filtered_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of items available 11664\n",
      "\n",
      " Sample item:\n",
      "item-B0002PYXA6 {u'A2NYK9KWFMJV4Y': (4.0, u\"The good first: these brushes have a heavier and thicker staccato sound than wire bristle brushes. That makes them perfect for Afro-Cuban and Brazilian music. As a substitute for wire brushes they work poorly because legato sweeps are not very distinct. As an additional tool, though they will add to your sound palette.What I do not like is the fact that they are 'throw out' style retractable brushes. You push the bristles into the handle to retract them and a throw motion will extend them. That in itself is clever, but if you use different fan outs for each hand this brush is a distraction. For example, I typically will keep the fan of my right brush tighter so I get a more staccato sound, while fully fanning out on the left one for a legato quarter note sweep. That is awkward to do with these the way they are designed.Physically these have a relatively thick handle at .579 inches, but it's light and the added thickness does lend itself to Afro-Cuban and Brazilian playing. The overall length is 13.75 inches, of which 5.25 inches are bristles. The balance is very nice. I have heard of handles cracking, but I have never experienced that. As far as construction these brushes appear to be well made and should last a long time of used properly (i.e., as brushes and not played like sticks.)\"), u'A1J7TNASRMM7RE': (5.0, u'I was very pleased with this product and I feel that they will last a long time. They worked great for what I needed.'), u'A3EWG5C5KW5W9C': (4.0, u\"They're kinda heavy and therefore a little louder, and they retract which saves alot of wear and tear, a good thing to have in the stick bag.\")}\n"
     ]
    }
   ],
   "source": [
    "def convert(data):\n",
    "    \n",
    "    \"\"\" convert the dictionary from {main_key{nested_key:value}} to {nested_key{main_key:value}}.\n",
    "    This conversion is to filter a dictionary in both way,eg user-item filter and item-user filter \"\"\"\n",
    "    \n",
    "    item_data = { }\n",
    "    for user in data:\n",
    "        for item in data[user]:\n",
    "            item_data.setdefault(item, {})\n",
    "            item_data[item][user] = data[user][item]\n",
    "    return item_data\n",
    "\n",
    "item_dict = convert(filtered_users)\n",
    "print \"Size of items available\" ,len(item_dict)\n",
    "\n",
    "print \"\\n Sample item:\"\n",
    "for i in item_dict:\n",
    "    print i ,  item_dict[i]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dict)filtered items with rating as values-> 774\n",
      "(list)unique users for filtered items with ratings as values-> 396\n",
      "item-B000B6FBA2 {u'A3FLOANV9JOFAM': (5.0, u'I am really pleased with the ease of use and accuracy of tone control.  Not just on 6 strings but on 12 string guitars, too.'), u'A3PGQWCSJPCYDH': (3.0, u'You have to turn the knobs every time you want to use this. What a pain. Oh well, it was cheap enough to have around.'), u'A2Z89YMZZJWBHS': (2.0, u\"I ordered one of these because I like my other Planet Waves Capo a lot (I believe its the older metal version of this, not the &#34;Lite&#34;). However, this one just does not screw down enough to hold down the strings, especially down at the lower frets where the neck is a little thinner (on a Martin jumbo acoustic). It will barely bend the strings down behind the fret but not enough to prevent buzzing. Your fretting hand will naturally push the capo back and out of position quite easily when playing open chords too.I'm not sure why the plastic version has this issue when it appears to have an identical design to the old metal one. It doesn't seem defective as no parts are bent or missing as far as I can tell. Unless I just happen to get one with a shorter than normal screw, I wouldn't recommend it for any guitar without a thick neck.My recommendation is the classic Kyser capo thats more dependable and quicker to apply and remove (it also attaches to your headstock effortlessly when not in use). If you are looking for the screw-down style, I would look for the older version of this and avoid the &#34;Lite&#34;.\"), u'A2RVY2GDMZHH4': (4.0, u'Was not sure about this one but it is darn easy to use and works quite well.  I still use the Kayser for most stuff but this is great for a backup.'), u'A10044ECXDUVKS': (5.0, u'In 40 years I have had every kind of capo out there. This is the right one. This one works. Buy one for each of your guitars and keep them in the case: they are well made and inexpensive enough.'), u'A3SDJ70H00OQCJ': (5.0, u'I don\\'t have a classical guitar, but I just got an inexpensive but really fun steel string guitar with a non-radiused fingerboard.  I\\'ve also got over a dozen capos (don\\'t ask!) but all are for radiused fingerboards.The fingerboards of most steel-string guitars--electric and acoustic--are radiused, that is, they are not flat.  They have a gentle curve to them, so gentle that many wouldn\\'t notice it unless they looked closely. Look up \"fingerboard\" in the Wikipedia for an excellent discussion and Google images for diagrams and pictures.Even though the curve is gentle, if a fingerboard is radiused, a capo must be curved, too, or the outside strings would not be pressed down properly and would buzz.  If a fingerboard is flat, like a classical guitar\\'s, the capo must be flat, too, or the center strings will not be pressed down properly and will buzz.If you\\'re not sure whether your guitar\\'s fingerboard is radiused, slide a ruler between two frets.  If it lies flat, then so is the fingerboard.  If it rocks, the fingerboard is radiused.I REALLY like this capo because of the way pressure is adjusted by turning the tension screw.  This makes it possible to exert just the right amount of pressure--not tool little, which would cause strings to buzz, and not too much, which would cause the instrument to go out of tune.As others have noted, its one drawback is that it can\\'t be clamped to the headstock when not in use.  But for that, I\\'d replace most of my capos with radiused versions of this capo.  HIGHLY recommended!'), u'A4XWMOFB1HY04': (5.0, u\"There's nothing not to like about this capo.  I have two of them.  I've played guitar for over 40 years and have used other types of capos.  I like this one's low profile and the fact that you provide the pressure to the fretboard (by turning a knob to tighten it) rather than rely on a spring, as on the clip-on type. It takes a few seconds longer to install than the clip-on type, but I like the results better.\")}\n",
      "774\n"
     ]
    }
   ],
   "source": [
    "'''filter item dict and then get unique set of users for the filtered items'''\n",
    "filtered_items, unique_users_for_filtered_item=filter_data(item_dict,2)\n",
    "\n",
    "print \"(dict)filtered items with rating as values->\",len(filtered_items)\n",
    "print \"(list)unique users for filtered items with ratings as values->\",len(unique_users_for_filtered_item)\n",
    "\n",
    "for i in filtered_items:\n",
    "    print i ,  filtered_items[i]\n",
    "    break\n",
    "    \n",
    "item_names = filtered_items.keys()\n",
    "print len(item_names)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reviews: 774\n",
      "\n",
      "Sample Review:\n",
      "I am really pleased with the ease of use and accuracy of tone control.  Not just on 6 strings but on 12 string guitars, too.\n"
     ]
    }
   ],
   "source": [
    "def get_movie_reviews_for_countVec(dict_to_use):\n",
    "    review_dict=[]\n",
    "\n",
    "    #print filtered_items.values()[0].values()\n",
    "    for i,item in enumerate(dict_to_use):\n",
    "      \n",
    "        for user in dict_to_use[item]:\n",
    "            #print dict_to_use[item][user][1]\n",
    "            review_dict.append(dict_to_use[item][user][1])\n",
    "            break\n",
    "\n",
    "    return review_dict\n",
    "    \n",
    "reviews_to_vectorize=get_movie_reviews_for_countVec(filtered_items)\n",
    "\n",
    "print \"Total Reviews:\" , len(reviews_to_vectorize)\n",
    "\n",
    "print  \"\\nSample Review:\\n\" , reviews_to_vectorize[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(774, 396)\n",
      "(396L, 774L)\n"
     ]
    }
   ],
   "source": [
    "def get_rating_csr_matrix(dict_to_convert):\n",
    "    \n",
    "    \"\"\" Given any dictionary, convert the dictionary to a csr matrix format\"\"\"\n",
    "    v = DictVectorizer(sparse=False)\n",
    "    list2 = [ ]\n",
    "    for each_value in dict_to_convert:\n",
    "        list2.append(dict_to_convert[each_value])\n",
    "    for l in list2:        \n",
    "        for key in l:            \n",
    "            l[key]=float(l[key][0])       \n",
    "    X = v.fit_transform(list2)\n",
    "    csr_ratings = csr_matrix(X)\n",
    "   \n",
    "    return csr_ratings\n",
    "\n",
    "#csr matrix of rating with items as rows and users as columns\n",
    "\n",
    "ratings = get_rating_csr_matrix(filtered_items)\n",
    "print ratings.shape\n",
    "\n",
    "csr_ratings=np.transpose(ratings.todense())\n",
    "print csr_ratings.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Item - Based Colloborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(774, 396)\n",
      "(396L, 774L)\n"
     ]
    }
   ],
   "source": [
    "def utility_matrix(dict_to_convert):\n",
    "    \"\"\" Given any dictionary, convert the dictionary to a csr matrix format\"\"\"\n",
    "    v = DictVectorizer(sparse=False)\n",
    "    list2 = [ ]\n",
    "    for each_value in dict_to_convert:\n",
    "        list2.append(dict_to_convert[each_value])\n",
    "    for l in list2:        \n",
    "        for key in l:            \n",
    "            l[key]=float(l[key])       \n",
    "    X = v.fit_transform(list2)\n",
    "    csr_ratings = csr_matrix(X)\n",
    "   \n",
    "    return csr_ratings\n",
    "\n",
    "#csr matrix of rating with items as rows and users as columns\n",
    "\n",
    "ratings = utility_matrix(filtered_items)\n",
    "print ratings.shape\n",
    "\n",
    "csr_ratings=np.transpose(ratings.todense())\n",
    "print csr_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  3.  0.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print ratings.todense()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the ratings matrix is very sparse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def boosted_similarity(data, user1, user2):\n",
    "    common_rate = [ ]\n",
    "    for i in data[user1]:\n",
    "        if i in data[user2]:\n",
    "            common_rate.append(i)\n",
    "    n = len(common_rate)\n",
    "    if n == 0: return 0\n",
    "    u1 = [data[user1][rate] for rate in common_rate]\n",
    "    u2 = [data[user2][rate] for rate in common_rate]\n",
    "    u1 = map(float,u1)\n",
    "    u2 = map(float,u2)\n",
    "    sum_u1 = sum([u1[i] for i in range(0,len(u1))])\n",
    "    sum_u2 = sum([u2[i] for i in range(0,len(u1))])\n",
    "    square_u1 = sum([u1[i]**2 for i in range(0,len(u1))])\n",
    "    square_u2 = sum([u2[i]**2 for i in range(0,len(u1))])\n",
    "    sum_both = sum(u1[i] * u2[i] for i in range(0,len(u1)))\n",
    "    s_xx = square_u1 - pow(sum_u1,2) / n\n",
    "    s_yy = square_u2 - pow(sum_u2,2) / n\n",
    "    num = sum_both / (sum_u1 * sum_u2 / n )\n",
    "    denom = sqrt( (s_xx * s_yy))\n",
    "    if denom == 0: \n",
    "        return 0\n",
    "    else: \n",
    "        score = num / denom\n",
    "    return score\n",
    "\n",
    "sim_scores = [ ]\n",
    "for i in range(0,len(user_id)-1):\n",
    "    score = boosted_similarity(cf_data, user_id[i], user_id[i+1])\n",
    "    sim_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score is 0.221785714286\n"
     ]
    }
   ],
   "source": [
    "score = boosted_similarity(cf_data, user_id[2206], user_id[2207])\n",
    "print \"similarity score is\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, steps=1000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in xrange(steps):\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    for k in xrange(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in xrange(K):\n",
    "                        e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def item_based(ratings):\n",
    "    \"\"\" Prediction of unknown ratings based on the existing ratings\"\"\"\n",
    "    R = np.array(ratings)\n",
    "    N = len(R)  \n",
    "    M = len(R[0])\n",
    "    K = 2\n",
    "    P = np.random.rand(N,K)\n",
    "    Q = np.random.rand(M,K)\n",
    "    nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "    predicted_rating = np.dot(nP, nQ.T)\n",
    "    return predicted_rating\n",
    "predict = item_based(ratings.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_MAE(true, predict):\n",
    "    \"\"\" compute mean absolute error\"\"\"\n",
    "    e = (true - predict )\n",
    "    error=np.linalg.norm(e)\n",
    "    return error\n",
    "\n",
    "def compute_MSE(true, predict):\n",
    "    \"\"\" compute mean squared error \"\"\"\n",
    "    error = (true - predict )**2    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 1.98270245749\n",
      "Mean Squared Error 1.70030425145\n",
      "Root Mean Squared Error 0.0468697719075\n"
     ]
    }
   ],
   "source": [
    "def evaluation(ratings,predict):\n",
    "    \"\"\" Evaluation of recommendation system \"\"\"\n",
    "    MAE = [ ]\n",
    "    MSE=[]\n",
    "    RMSE=[]\n",
    "    precision=[]\n",
    "    ratings_copy = ratings.copy()\n",
    "    predict_copy = predict.copy()\n",
    "    for i in range(0,ratings_copy.shape[0]):\n",
    "        for j in range(0,ratings_copy.shape[1]):\n",
    "            if ratings_copy[i,j] != 0.:\n",
    "                mae = compute_MAE(ratings_copy[i,j],predict_copy[i,j])\n",
    "                MAE.append(mae)\n",
    "                mse=compute_MSE(ratings_copy[i,j],predict_copy[i,j])\n",
    "                MSE.append(mse)                \n",
    "    mean_abs_error = np.sum(MAE) / ratings_copy.todense().shape[0]\n",
    "    mean_sq_error = np.sum(MSE) / ratings_copy.todense().shape[0]\n",
    "    root_mean_sq_error = (np.sum(MSE))**0.5 / ratings_copy.todense().shape[0]\n",
    "    return mean_abs_error,mean_sq_error,root_mean_sq_error\n",
    "MAE,MSE,RMSE = evaluation(ratings,predict)\n",
    "print \"Mean Absolute Error\", MAE\n",
    "print \"Mean Squared Error\",MSE\n",
    "print \"Root Mean Squared Error\",RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted items for user 396\n",
      "user A3CRG8NYUSK9PS\n",
      "Item recommended item-B00EUEWR2G\n"
     ]
    }
   ],
   "source": [
    "def item_recommended_user(ratings,predict,item_names):\n",
    "    ratings_copy = ratings.copy()\n",
    "    predict_copy = predict.copy()\n",
    "    predicted_scores = {}\n",
    "    rec_item_list=[]\n",
    "    for i in range(0,ratings_copy.shape[0]):\n",
    "        temp_list=list(predict[i])\n",
    "        ind=temp_list.index(max(temp_list))\n",
    "        if ratings_copy[i,ind] == 0.:\n",
    "            predicted_scores[unique_users_for_filtered_item[i]]=item_names[ind]\n",
    "        else:\n",
    "            temp_list.pop(ind) \n",
    "            ind2=temp_list.index(max(temp_list))\n",
    "            predicted_scores[unique_users_for_filtered_item[i]]=item_names[ind2]             \n",
    "    return predicted_scores\n",
    "predicted_items_for_users=item_recommended_user(ratings.T,predict.T,item_names)\n",
    "print \"Predicted items for user\", len(predicted_items_for_users)\n",
    "for user in predicted_items_for_users:\n",
    "    print \"user\" , user\n",
    "    print \"Item recommended\", predicted_items_for_users[user]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_recommendation(ratings,predict,item_names):\n",
    "    \"\"\" Top recommendation for the users \"\"\"\n",
    "    ratings_copy = ratings.copy()\n",
    "    predict_copy = predict.copy()\n",
    "    scores = { }\n",
    "    for i in range(0,ratings_copy.shape[0]):\n",
    "        output1 = [ ]\n",
    "        for j in range(0,ratings_copy.shape[1]):\n",
    "            if ratings_copy[i,j] == 0.:\n",
    "                output1.append((item_names[j],predict_copy[i,j]))\n",
    "        output1.sort()\n",
    "        output1.reverse()\n",
    "        scores[unique_users_for_filtered_item[i]] = output1[0:5]\n",
    "    return scores\n",
    "top_recommendations = top_recommendation(ratings.T,predict.T,item_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " User: A3CRG8NYUSK9PS\n",
      "\n",
      "Top 5 item recommendations: \n",
      "item-B00JBIVXGC\n",
      "item-B00IZCSW3M\n",
      "item-B00IAD18NM\n",
      "item-B00HFRXACG\n",
      "item-B00GTSM8FW\n"
     ]
    }
   ],
   "source": [
    "for user in top_recommendations:\n",
    "    print \" User:\" , user\n",
    "    print \"\\nTop 5 item recommendations: \" \n",
    "    for item in top_recommendations[user]:\n",
    "        print item[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 774)\n"
     ]
    }
   ],
   "source": [
    "user_matrix=csr_matrix(np.transpose(ratings.todense()))\n",
    "print user_matrix.shape\n",
    "predict = item_based(user_matrix.todense())\n",
    "MAE,MSE,RMSE = evaluation(user_matrix,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 3.84303607339\n",
      "Mean Squared Error 3.26310460595\n",
      "Root Mean Squared Error 0.0907753443746\n"
     ]
    }
   ],
   "source": [
    "print \"Mean Absolute Error\", MAE\n",
    "print \"Mean Squared Error\",MSE\n",
    "print \"Root Mean Squared Error\",RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review:\n",
      "The portfolio is fine except for the fact that the last movement of sonata #6 is missing. What should one expect?\n",
      "\n",
      "List of tokens:\n",
      "[u'the', u'portfolio', u'is', u'fine', u'except', u'for', u'the', u'fact', u'that', u'the', u'last', u'movement', u'of', u'sonata', u'6', u'is', u'missing', u'what', u'should', u'one', u'expect']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Given a string, return a list of tokens such that: (1) all\n",
    "    tokens are lowercase, (2) all punctuation is removed. Note that underscore (_) \n",
    "    is not considered punctuation.\n",
    "    \"\"\"\n",
    "    e=text.lower()\n",
    "    t=re.sub(r'[^\\x00-\\x7F]+',' ', e)\n",
    "    tokens = re.sub('\\W+', ' ', t).split()\n",
    "\n",
    "    return tokens\n",
    "print \"Sample review:\"\n",
    "print reviews[0]+\"\\n\"\n",
    "token=tokenize(reviews[0])\n",
    "print \"List of tokens:\"\n",
    "print token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am really pleased with the ease of use and accuracy of tone control.  Not just on 6 strings but on 12 string guitars, too.\n",
      "\n",
      " matrix represents 774 documents with 12149 features\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Convert a list of reviews into a sparse csr_matrix, where each row is a review and each \n",
    "column represents a unique word.\"\"\"\n",
    "def do_vectorize(review_list, tokenizer_fn=tokenize, min_df=1,\n",
    "                 max_df=1., binary=True, ngram_range=(1,1)):\n",
    "    vec=CountVectorizer(review_list,tokenizer=tokenizer_fn, min_df=min_df,max_df=max_df, binary=binary, \n",
    "                        ngram_range=ngram_range,dtype=float)\n",
    "    matrix=vec.fit_transform(review_list)\n",
    "    return matrix,vec\n",
    "\n",
    "print reviews_to_vectorize[0]\n",
    "matrix, vec = do_vectorize(reviews_to_vectorize)\n",
    "print ('\\n matrix represents %d documents with %d features' % (matrix.shape[0], matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.  10.   2. ...,   3.   1.   2.]\n"
     ]
    }
   ],
   "source": [
    "def document_frequencies(movie_term_matrix):\n",
    "    \"\"\" Compute the number of different reviews that each term appears in.It returns numpy array with \n",
    "    one element per term in the vocabulary.\"\"\"\n",
    "    \n",
    "    X = movie_term_matrix.copy()\n",
    "    (i,j) = X.nonzero()\n",
    "    col_sums = np.zeros(X.shape[1])\n",
    "    for n in np.asarray(j):\n",
    "        col_sums[n] += 1.\n",
    "    return col_sums\n",
    "    \n",
    "dfs = document_frequencies(matrix)\n",
    "print dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf(movie_term_matrix, dfs):\n",
    "    \"\"\" Create a new matrix that transforms item_term_matrix using tfidf.\n",
    "    Simply divide each value by the document frequency for that term.\n",
    "      A csr_matrix that is a copy of term_matrix where value\n",
    "      i,j is divided by the document frequency of term j\"\"\"\n",
    "      \n",
    "    x = movie_term_matrix.copy()\n",
    "    x=x/dfs\n",
    "    a = csr_matrix(x)\n",
    "    return a\n",
    " \n",
    "# tfidf matrix: row=movie, col=term\n",
    "\n",
    "tfidf_matrix = tfidf(matrix, dfs)\n",
    "tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(774, 12149)\n",
      "(396L, 774L)\n"
     ]
    }
   ],
   "source": [
    "print tfidf_matrix.shape\n",
    "print csr_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utility matrix (396L, 774L)\n",
      "prediction matrix (396L, 774L)\n",
      "tfidf matrix (774, 12149)\n",
      "csr matrix (396, 12149)\n",
      "\n",
      "User profile Matrix:\n",
      "[[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.03333333  0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def make_user_profiles(ratings, tfidf_matrix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a user profile matrix by computing the weighted average of the tfidf\n",
    "    vectors of each item user has rated. E.g., if a person has rated \n",
    "    one item .2 with tfidf vector ([.1, .3]) and rated another item\n",
    "    .6 with tfidf vector([.2, .4]), then the weighted average is: [(.2*.1 + .6*.2) / (.2 + .6), (.2*.3 + .6*.4) / (.2 + .6)]\n",
    "     Returns: A csr matrix where each row represents a user and the columns represent terms.\n",
    "    \"\"\"\n",
    "    X = ratings * tfidf_matrix\n",
    "    s=ratings.sum(axis=1)\n",
    "    X=X/s\n",
    "    a = csr_matrix(X)\n",
    "    return a\n",
    "print \"utility matrix\",csr_ratings.shape\n",
    "print \"prediction matrix\",predict.T.shape\n",
    "print \"tfidf matrix\",tfidf_matrix.shape\n",
    "user_profiles = make_user_profiles(csr_matrix(ratings.T), tfidf_matrix)\n",
    "print \"csr matrix\" , user_profiles.shape\n",
    "print \"\\nUser profile Matrix:\"\n",
    "print user_profiles.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm(vector):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of one row of a csr_matrix.\n",
    "    https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm\n",
    "    \"\"\"\n",
    "    total=0\n",
    "    data= vector.data\n",
    "    for i in data:\n",
    "        square = np.dot(i,i)\n",
    "        total += square\n",
    "    return np.sqrt(total)\n",
    "    \n",
    "norm(csr_matrix([3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99451"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine(v1, v2):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors (rows from a csr_matrix).\n",
    "    https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    vec1 = v1.toarray()\n",
    "    vec2 = v2.toarray()\n",
    "    numer = np.vdot(vec1,vec2)\n",
    "    denom = norm(v1) * norm(v2)\n",
    "    return numer / denom  \n",
    "    \n",
    "round(cosine(csr_matrix([2,4]), csr_matrix([3,8])), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 12149)\n",
      "(774, 12149)\n",
      "(396, 774)\n"
     ]
    }
   ],
   "source": [
    "print user_profiles.shape \n",
    "print tfidf_matrix.shape \n",
    "print ratings.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396L, 774L)\n"
     ]
    }
   ],
   "source": [
    "def predict_ratings_w_user_profiles(ratings, user_profiles, tfidf_matrix, bias =3.96):\n",
    "    \"\"\"\n",
    "    Make a copy of the ratings matrix. Replace each all the entries with a predicted score\n",
    "    based on user_profile. Specifically, the ratings of user i for item j is the \n",
    "    cosine similarity between user i's profile and item's j tfidf vector.\n",
    "    \"\"\"\n",
    "    ratings_copy = ratings.copy()\n",
    "    for i in range(0,ratings_copy.shape[0]):\n",
    "        for j in range(0,ratings_copy.shape[1]):\n",
    "            if ratings_copy[i,j] == 0.:\n",
    "                ratings_copy[i,j] = cosine(user_profiles[i],tfidf_matrix[j])\n",
    "    ratings_copy = ratings_copy.todense() + bias\n",
    "    return ratings_copy  \n",
    "    \n",
    "content_predict = predict_ratings_w_user_profiles(ratings.T, user_profiles, tfidf_matrix)\n",
    "print content_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 34.29\n",
      "Mean Squared Error 135.7884\n",
      "Root Mean Squared Error 0.585576638878\n"
     ]
    }
   ],
   "source": [
    "MAE,MSE,RMSE = evaluation(ratings.T,content_predict)\n",
    "print \"Mean Absolute Error\", MAE\n",
    "print \"Mean Squared Error\",MSE\n",
    "print \"Root Mean Squared Error\",RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csr matrix (396, 12149)\n",
      "\n",
      "User profile Matrix:\n",
      "[[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.03333333  0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def hybrid_recommendation (cf_ratings ,ratings, tfidf_matrix):\n",
    "    \"\"\"\n",
    "    Create a user profile matrix by computing the weighted average of the tfidf\n",
    "    vectors of each item user has rated.\n",
    "    \"\"\"\n",
    "    user_profiles = make_user_profiles(csr_matrix(ratings.T), tfidf_matrix)    \n",
    "    print \"csr matrix\" , user_profiles.shape\n",
    "    print \"\\nUser profile Matrix:\"\n",
    "    print user_profiles.todense()\n",
    "    content_predict = predict_ratings_w_user_profiles(ratings.T, user_profiles, tfidf_matrix)\n",
    "    content_predict = csr_matrix(content_predict)\n",
    "    hybrid_predict = item_based(content_predict.todense())\n",
    "    return hybrid_predict\n",
    "hybrid_predict = hybrid_recommendation (csr_matrix(predict), ratings, tfidf_matrix)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 7.21636520021\n",
      "Mean Squared Error 8.6374124446\n",
      "Root Mean Squared Error 0.147687669043\n"
     ]
    }
   ],
   "source": [
    "MAE,MSE,RMSE = evaluation(ratings.T, hybrid_predict)\n",
    "print \"Mean Absolute Error\", MAE\n",
    "print \"Mean Squared Error\",MSE\n",
    "print \"Root Mean Squared Error\",RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
